{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhux/mikayla/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Invalid value: File does not exist: mpq_chatbot.py\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'faiss' has no attribute 'IndexFlatL2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m faq_questions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(faq\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     39\u001b[0m faq_embeddings \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mencode(faq_questions, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexFlatL2\u001b[49m(faq_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     41\u001b[0m index\u001b[38;5;241m.\u001b[39madd(faq_embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Initialize session state\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'faiss' has no attribute 'IndexFlatL2'"
     ]
    }
   ],
   "source": [
    "# model_name = \"distilbert-base-uncased\"  # or \"bert-base-uncased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "#%pip install streamlit\n",
    "#%pip install faiss-cpu\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "os.system(\"streamlit run mpq_chatbot.py &\")\n",
    "\n",
    "# Load DistilBERT-based embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sample MPQ questions\n",
    "mpq_questions = [\n",
    "    \"Describe your pain in your own words.\",\n",
    "    \"Is the pain throbbing, shooting, stabbing, or burning?\",\n",
    "    \"How intense is your pain on a scale of 1-10?\",\n",
    "    \"Does the pain get worse with movement or at rest?\",\n",
    "    \"How does the pain affect your emotions?\",\n",
    "]\n",
    "\n",
    "# Predefined answers to common patient questions\n",
    "faq = {\n",
    "    \"What is this questionnaire for?\": \"The McGill Pain Questionnaire helps doctors assess the nature of your pain.\",\n",
    "    \"What does 'throbbing' mean?\": \"Throbbing pain is like a steady or pulsing ache.\",\n",
    "    \"Can I skip a question?\": \"Yes, but answering all questions helps provide a full picture of your pain.\",\n",
    "}\n",
    "\n",
    "# Encode FAQ for similarity search\n",
    "faq_questions = list(faq.keys())\n",
    "faq_embeddings = embedding_model.encode(faq_questions, convert_to_tensor=True)\n",
    "index = faiss.IndexFlatL2(faq_embeddings.shape[1])\n",
    "index.add(faq_embeddings.cpu().numpy())\n",
    "\n",
    "# Initialize session state\n",
    "if \"step\" not in st.session_state:\n",
    "    st.session_state[\"step\"] = 0\n",
    "if \"responses\" not in st.session_state:\n",
    "    st.session_state[\"responses\"] = []\n",
    "\n",
    "if \"submitted\" not in st.session_state:\n",
    "    st.session_state[\"submitted\"] = False\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"McGill Pain Questionnaire Facilitator\")\n",
    "\n",
    "# Display current question\n",
    "if st.session_state[\"step\"] < len(mpq_questions):\n",
    "    question = mpq_questions[st.session_state[\"step\"]]\n",
    "    st.subheader(question)\n",
    "\n",
    "    user_input = st.text_input(\"Your response:\", \"\")\n",
    "\n",
    "    if st.button(\"Submit\"):\n",
    "        if user_input.strip():\n",
    "            # Check if user asked a question\n",
    "            input_embedding = embedding_model.encode(user_input, convert_to_tensor=True)\n",
    "            D, I = index.search(input_embedding.cpu().numpy().reshape(1, -1), 1)\n",
    "            if D[0][0] < 0.5:  # Threshold for similarity\n",
    "                st.write(f\"ðŸ¤– {faq[faq_questions[I[0][0]]]}\")  # Answer detected question\n",
    "            else:\n",
    "                st.session_state[\"responses\"].append((question, user_input))\n",
    "                st.session_state[\"step\"] += 1\n",
    "                st.session_state[\"submitted\"] = True  # Mark as submitted to prevent re-submission\n",
    "                st.experimental_rerun() \n",
    "\n",
    "# Show summary when complete\n",
    "if st.session_state[\"step\"] >= len(mpq_questions):\n",
    "    st.subheader(\"Summary of Your Responses\")\n",
    "    for q, r in st.session_state[\"responses\"]:\n",
    "        st.write(f\"**{q}**\\n{r}\\n\")\n",
    "    st.success(\"Thank you for completing the questionnaire!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st \n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "torch.classes.__path__ = []\n",
    "\n",
    "# Load DistilBERT-based embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sample MPQ questions\n",
    "mpq_questions = [\n",
    "    \"Describe your pain in your own words.\",\n",
    "    \"Is the pain throbbing, shooting, stabbing, or burning?\",\n",
    "    \"How intense is your pain on a scale of 1-10?\",\n",
    "    \"Does the pain get worse with movement or at rest?\",\n",
    "    \"How does the pain affect your emotions?\",\n",
    "]\n",
    "\n",
    "# Predefined answers to common patient questions\n",
    "faq = {\n",
    "    \"What is this questionnaire for?\": \"The McGill Pain Questionnaire helps doctors assess the nature of your pain.\",\n",
    "    \"What does 'throbbing' mean?\": \"Throbbing pain is like a steady or pulsing ache.\",\n",
    "    \"Can I skip a question?\": \"Yes, but answering all questions helps provide a full picture of your pain.\",\n",
    "}\n",
    "\n",
    "# Encode FAQ for similarity search\n",
    "faq_questions = list(faq.keys())\n",
    "faq_embeddings = embedding_model.encode(faq_questions, convert_to_tensor=True)\n",
    "index = faiss.IndexFlatL2(faq_embeddings.shape[1])\n",
    "index.add(faq_embeddings.cpu().numpy())\n",
    "\n",
    "# Initialize session state\n",
    "if \"responses\" not in st.session_state:\n",
    "    st.session_state[\"responses\"] = {}\n",
    "\n",
    "st.title(\"McGill Pain Questionnaire\")\n",
    "\n",
    "# Use a form for input\n",
    "with st.form(key=\"mpq_form\"):\n",
    "    responses = {}\n",
    "    for question in mpq_questions:\n",
    "        responses[question] = st.text_input(question, value=\"\", key=question)\n",
    "\n",
    "    submitted = st.form_submit_button(\"Submit\")\n",
    "\n",
    "if submitted:\n",
    "    # Process responses\n",
    "    for question, user_input in responses.items():\n",
    "        if user_input.strip():\n",
    "            input_embedding = embedding_model.encode(user_input, convert_to_tensor=True)\n",
    "            D, I = index.search(input_embedding.cpu().numpy().reshape(1, -1), 1)\n",
    "            if D[0][0] < 0.5:  # Threshold for similarity\n",
    "                st.write(f\"ðŸ¤– {faq[faq_questions[I[0][0]]]}\")  # Answer detected question\n",
    "            else:\n",
    "                st.session_state[\"responses\"][question] = user_input\n",
    "\n",
    "    # Show summary\n",
    "    st.subheader(\"Summary of Your Responses\")\n",
    "    for q, r in st.session_state[\"responses\"].items():\n",
    "        st.write(f\"**{q}**\\n{r}\\n\")\n",
    "    \n",
    "    st.success(\"Thank you for completing the questionnaire!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st \n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "torch.classes.__path__ = []\n",
    "\n",
    "# Load DistilBERT-based embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sample MPQ questions\n",
    "mpq_questions = [\n",
    "    \"Describe your pain in your own words.\",\n",
    "    \"Is the pain throbbing, shooting, stabbing, or burning?\",\n",
    "    \"How intense is your pain on a scale of 1-10?\",\n",
    "    \"Does the pain get worse with movement or at rest?\",\n",
    "    \"How does the pain affect your emotions?\",\n",
    "]\n",
    "\n",
    "# Predefined answers to common patient questions\n",
    "faq = {\n",
    "    \"What is this questionnaire for?\": \"The McGill Pain Questionnaire helps doctors assess the nature of your pain.\",\n",
    "    \"What does 'throbbing' mean?\": \"Throbbing pain is like a steady or pulsing ache.\",\n",
    "    \"Can I skip a question?\": \"Yes, but answering all questions helps provide a full picture of your pain.\",\n",
    "}\n",
    "\n",
    "# Encode FAQ for similarity search\n",
    "faq_questions = list(faq.keys())\n",
    "faq_embeddings = embedding_model.encode(faq_questions, convert_to_tensor=True)\n",
    "index = faiss.IndexFlatL2(faq_embeddings.shape[1])\n",
    "index.add(faq_embeddings.cpu().numpy())\n",
    "\n",
    "# Initialize session state\n",
    "if \"step\" not in st.session_state:\n",
    "    st.session_state[\"step\"] = 0\n",
    "if \"responses\" not in st.session_state:\n",
    "    st.session_state[\"responses\"] = {}\n",
    "\n",
    "st.title(\"McGill Pain Questionnaire\")\n",
    "\n",
    "# Check if questionnaire is completed\n",
    "if st.session_state[\"step\"] < len(mpq_questions):\n",
    "    question = mpq_questions[st.session_state[\"step\"]]\n",
    "    st.subheader(question)\n",
    "\n",
    "    # Chat interaction\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state[\"chat_history\"] = []\n",
    "\n",
    "    for msg in st.session_state[\"chat_history\"]:\n",
    "        st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "    # User input\n",
    "    user_input = st.chat_input(\"Type your response or ask a question...\")\n",
    "\n",
    "    if user_input:\n",
    "        # Store chat history\n",
    "        st.session_state[\"chat_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Check if user asked a question\n",
    "        input_embedding = embedding_model.encode(user_input, convert_to_tensor=True)\n",
    "        D, I = index.search(input_embedding.cpu().numpy().reshape(1, -1), 1)\n",
    "\n",
    "        if D[0][0] < 0.5:  # User asked an FAQ\n",
    "            answer = faq[faq_questions[I[0][0]]]\n",
    "            st.session_state[\"chat_history\"].append({\"role\": \"bot\", \"content\": answer})\n",
    "            st.chat_message(\"bot\").write(answer)\n",
    "        else:\n",
    "            # Save valid response and proceed to next question\n",
    "            st.session_state[\"responses\"][question] = user_input\n",
    "            st.session_state[\"step\"] += 1\n",
    "            st.session_state[\"chat_history\"] = []  # Clear chat for next question\n",
    "            st.rerun()\n",
    "\n",
    "else:\n",
    "    # Show summary of responses\n",
    "    st.subheader(\"Summary of Your Responses\")\n",
    "    for q, r in st.session_state[\"responses\"].items():\n",
    "        st.write(f\"**{q}**\\n{r}\\n\")\n",
    "    \n",
    "    st.success(\"Thank you for completing the questionnaire!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
