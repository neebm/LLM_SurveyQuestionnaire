{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'faiss' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'faiss' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# model_name = \"distilbert-base-uncased\"  # or \"bert-base-uncased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "#%pip install streamlit\n",
    "#%pip install faiss-cpu\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "os.system(\"streamlit run mpq_chatbot.py &\")\n",
    "\n",
    "# Load DistilBERT-based embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sample MPQ questions\n",
    "mpq_questions = [\n",
    "    \"Describe your pain in your own words.\",\n",
    "    \"Is the pain throbbing, shooting, stabbing, or burning?\",\n",
    "    \"How intense is your pain on a scale of 1-10?\",\n",
    "    \"Does the pain get worse with movement or at rest?\",\n",
    "    \"How does the pain affect your emotions?\",\n",
    "]\n",
    "\n",
    "# Predefined answers to common patient questions\n",
    "faq = {\n",
    "    \"What is this questionnaire for?\": \"The McGill Pain Questionnaire helps doctors assess the nature of your pain.\",\n",
    "    \"What does 'throbbing' mean?\": \"Throbbing pain is like a steady or pulsing ache.\",\n",
    "    \"Can I skip a question?\": \"Yes, but answering all questions helps provide a full picture of your pain.\",\n",
    "}\n",
    "\n",
    "# Encode FAQ for similarity search\n",
    "faq_questions = list(faq.keys())\n",
    "faq_embeddings = embedding_model.encode(faq_questions, convert_to_tensor=True)\n",
    "index = faiss.IndexFlatL2(faq_embeddings.shape[1])\n",
    "index.add(faq_embeddings.cpu().numpy())\n",
    "\n",
    "# Initialize session state\n",
    "if \"step\" not in st.session_state:\n",
    "    st.session_state[\"step\"] = 0\n",
    "if \"responses\" not in st.session_state:\n",
    "    st.session_state[\"responses\"] = []\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"McGill Pain Questionnaire Facilitator\")\n",
    "\n",
    "# Display current question\n",
    "if st.session_state[\"step\"] < len(mpq_questions):\n",
    "    question = mpq_questions[st.session_state[\"step\"]]\n",
    "    st.subheader(question)\n",
    "\n",
    "    user_input = st.text_input(\"Your response:\", \"\")\n",
    "\n",
    "    if st.button(\"Submit\"):\n",
    "        if user_input.strip():\n",
    "            # Check if user asked a question\n",
    "            input_embedding = embedding_model.encode(user_input, convert_to_tensor=True)\n",
    "            D, I = index.search(input_embedding.cpu().numpy().reshape(1, -1), 1)\n",
    "            if D[0][0] < 0.5:  # Threshold for similarity\n",
    "                st.write(f\"ðŸ¤– {faq[faq_questions[I[0][0]]]}\")  # Answer detected question\n",
    "            else:\n",
    "                st.session_state[\"responses\"].append((question, user_input))\n",
    "                st.session_state[\"step\"] += 1\n",
    "\n",
    "# Show summary when complete\n",
    "if st.session_state[\"step\"] >= len(mpq_questions):\n",
    "    st.subheader(\"Summary of Your Responses\")\n",
    "    for q, r in st.session_state[\"responses\"]:\n",
    "        st.write(f\"**{q}**\\n{r}\\n\")\n",
    "    st.success(\"Thank you for completing the questionnaire!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
